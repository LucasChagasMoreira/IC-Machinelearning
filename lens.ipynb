{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12409,"status":"ok","timestamp":1690934657648,"user":{"displayName":"LUCAS CHAGAS MOREIRA","userId":"17970820584704249691"},"user_tz":180},"id":"OO6xaO5BPATU","outputId":"3c489f67-35e5-45ca-bb91-f63de57021f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n","Collecting timm\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Collecting huggingface-hub (from timm)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: safetensors, huggingface-hub, timm\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 timm-0.9.2\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from __future__ import print_function\n","import numpy as np\n","!pip install efficientnet_pytorch\n","!pip install timm\n","\n","import pandas as pd\n","from google.colab import drive\n","import torch\n","import torch.nn as nn\n","import os\n","from efficientnet_pytorch import EfficientNet\n","import torch.optim as optim\n","import glob\n","from itertools import chain\n","import os\n","import random\n","import zipfile\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, transforms\n","from tqdm.notebook import tqdm\n","\n","\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RI0ebsl9YKS"},"outputs":[],"source":["import torch\n","from torchvision import transforms\n","import pandas as pd\n","import os\n","\n","def load_data(data_file, data_dir='/content/drive/Shareddrives/IC - Datasets/dataset/lens/',\n","              img_ext='.bmp', img_shape=(224, 224)):\n","\n","    class_mapper = {'Colored': 0, 'Normal': 1, 'Transparent': 2}\n","    data = []\n","    labels = []\n","\n","    file_content = pd.read_csv(data_file, skiprows=[0], sep=',')\n","    len_file = len(file_content)\n","\n","    transform = transforms.Compose([\n","        transforms.RandomRotation(10),  # Rotação aleatória de até 10 graus\n","        transforms.RandomHorizontalFlip(),  # Espelhamento horizontal aleatório\n","        transforms.RandomVerticalFlip(),  # Espelhamento vertical aleatório\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Ajuste aleatório de brilho, contraste, saturação e tom\n","        transforms.RandomResizedCrop(input_shape[0]),  # Recorte aleatório redimensionado para o tamanho de entrada\n","        transforms.ToTensor(),  # Converter a imagem em tensor\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizar os valores dos canais RGB\n","    ])\n","\n","    for e, row in file_content.iterrows():\n","        img_path = os.path.join(data_dir, row[0]) + img_ext\n","        image = Image.open(img_path).convert('RGB')\n","        image = transform(image)\n","        label = class_mapper[row[1]]\n","\n","        data.append(image)\n","        labels.append(label)\n","\n","    data = torch.stack(data)\n","    labels = torch.tensor(labels)\n","\n","    return data, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1109535,"status":"ok","timestamp":1690934643435,"user":{"displayName":"LUCAS CHAGAS MOREIRA","userId":"17970820584704249691"},"user_tz":180},"id":"1kUJKFPnAz-x","outputId":"72d47265-af11-4a63-afd4-dfc6735f124b"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: torch.Size([1752, 3, 224, 224]) - y_train shape: torch.Size([1752])\n","x_test shape: torch.Size([1754, 3, 224, 224]) - y_test shape: torch.Size([1754])\n"]}],"source":["data_dir = '/content/drive/Shareddrives/IC - Datasets/dataset/lens/'\n","train_data_file = os.path.join(data_dir, 'CogentAnnotationTrain.csv')\n","test_data_file = os.path.join(data_dir, 'CogentAnnotationTest.csv')\n","\n","num_classes = 3\n","input_shape = (224, 224, 3)\n","# Parâmetros de treinamento\n","learning_rate = 0.001\n","batch_size = 16\n","epochs = 10\n","\n","x_train, y_train = load_data(train_data_file, data_dir=data_dir, img_shape=input_shape)\n","x_test, y_test = load_data(test_data_file, data_dir=data_dir, img_shape=input_shape)\n","\n","train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","\n","print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n","print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8h26-aAtahhe","executionInfo":{"status":"ok","timestamp":1690941422418,"user_tz":180,"elapsed":601495,"user":{"displayName":"LUCAS CHAGAS MOREIRA","userId":"17970820584704249691"}},"outputId":"4d1cc5cb-6591-42d5-fe9f-a0da4dbc2b69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - Loss: 1.5687 - Accuracy: 0.3205\n","Epoch 2/10 - Loss: 1.2044 - Accuracy: 0.3290\n","Epoch 3/10 - Loss: 1.1327 - Accuracy: 0.3517\n","Epoch 4/10 - Loss: 1.1126 - Accuracy: 0.3557\n","Epoch 5/10 - Loss: 1.1120 - Accuracy: 0.3545\n","Epoch 6/10 - Loss: 1.1058 - Accuracy: 0.3693\n","Epoch 7/10 - Loss: 1.1128 - Accuracy: 0.3585\n","Epoch 8/10 - Loss: 1.1099 - Accuracy: 0.3727\n","Epoch 9/10 - Loss: 1.0998 - Accuracy: 0.3750\n","Epoch 10/10 - Loss: 1.1088 - Accuracy: 0.3619\n"]}],"source":["import timm\n","import torchvision.transforms as transforms\n","\n","\n","# Definir o modelo ViT e o extrator de características\n","model = timm.create_model('vit_base_patch16_224', pretrained=True)  # Carregar o modelo ViT pré-treinado\n","transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224)])  # Pré-processar as imagens\n","\n","class ViTCNN(nn.Module):\n","    def __init__(self):\n","        super(ViTCNN, self).__init__()\n","        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n","\n","    def forward(self, x):\n","        outputs = self.vit(x)\n","        return outputs\n","\n","model = ViTCNN()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","def accuracy(outputs, labels):\n","    _, predicted = torch.max(outputs, dim=1)\n","    correct = (predicted == labels).sum().item()\n","    total = labels.size(0)\n","    return correct / total\n","\n","def train(model, train_loader, criterion, optimizer, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        running_accuracy = 0.0\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)  # Mover os dados de entrada para a GPU\n","            labels = labels.to(device)  # Mover os rótulos para a GPU\n","            optimizer.zero_grad()\n","            inputs = transform(inputs)  # Pré-processar as imagens usando o transform\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            running_accuracy += accuracy(outputs, labels)\n","        epoch_loss = running_loss / len(train_loader)\n","        epoch_accuracy = running_accuracy / len(train_loader)\n","        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f}\")\n","\n","train(model, train_loader, criterion, optimizer, 10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":974114,"status":"ok","timestamp":1690938263765,"user":{"displayName":"LUCAS CHAGAS MOREIRA","userId":"17970820584704249691"},"user_tz":180},"id":"GDKLz4slfp0c","outputId":"a4854fad-80c0-403c-d22f-28ac15bdba79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b3\n","Epoch 1/40 - Loss: 1.1850 - Accuracy: 0.5602\n","Epoch 2/40 - Loss: 0.6265 - Accuracy: 0.6943\n","Epoch 3/40 - Loss: 0.5344 - Accuracy: 0.7597\n","Epoch 4/40 - Loss: 0.4093 - Accuracy: 0.8250\n","Epoch 5/40 - Loss: 0.3707 - Accuracy: 0.8517\n","Epoch 6/40 - Loss: 0.3321 - Accuracy: 0.8773\n","Epoch 7/40 - Loss: 0.2558 - Accuracy: 0.9017\n","Epoch 8/40 - Loss: 0.2268 - Accuracy: 0.9040\n","Epoch 9/40 - Loss: 0.2079 - Accuracy: 0.9239\n","Epoch 10/40 - Loss: 0.2126 - Accuracy: 0.9176\n","Epoch 11/40 - Loss: 0.1859 - Accuracy: 0.9301\n","Epoch 12/40 - Loss: 0.1374 - Accuracy: 0.9477\n","Epoch 13/40 - Loss: 0.1664 - Accuracy: 0.9386\n","Epoch 14/40 - Loss: 0.1392 - Accuracy: 0.9523\n","Epoch 15/40 - Loss: 0.1107 - Accuracy: 0.9619\n","Epoch 16/40 - Loss: 0.0939 - Accuracy: 0.9665\n","Epoch 17/40 - Loss: 0.1034 - Accuracy: 0.9614\n","Epoch 18/40 - Loss: 0.0996 - Accuracy: 0.9625\n","Epoch 19/40 - Loss: 0.1437 - Accuracy: 0.9449\n","Epoch 20/40 - Loss: 0.0777 - Accuracy: 0.9716\n","Epoch 21/40 - Loss: 0.0611 - Accuracy: 0.9784\n","Epoch 22/40 - Loss: 0.1121 - Accuracy: 0.9631\n","Epoch 23/40 - Loss: 0.1061 - Accuracy: 0.9693\n","Epoch 24/40 - Loss: 0.1363 - Accuracy: 0.9563\n","Epoch 25/40 - Loss: 0.0775 - Accuracy: 0.9688\n","Epoch 26/40 - Loss: 0.0764 - Accuracy: 0.9705\n","Epoch 27/40 - Loss: 0.0627 - Accuracy: 0.9801\n","Epoch 28/40 - Loss: 0.0458 - Accuracy: 0.9818\n","Epoch 29/40 - Loss: 0.0469 - Accuracy: 0.9852\n","Epoch 30/40 - Loss: 0.0718 - Accuracy: 0.9784\n","Epoch 31/40 - Loss: 0.0471 - Accuracy: 0.9824\n","Epoch 32/40 - Loss: 0.0630 - Accuracy: 0.9830\n","Epoch 33/40 - Loss: 0.0827 - Accuracy: 0.9744\n","Epoch 34/40 - Loss: 0.1213 - Accuracy: 0.9574\n","Epoch 35/40 - Loss: 0.0408 - Accuracy: 0.9875\n","Epoch 36/40 - Loss: 0.0235 - Accuracy: 0.9943\n","Epoch 37/40 - Loss: 0.0063 - Accuracy: 0.9983\n","Epoch 38/40 - Loss: 0.0630 - Accuracy: 0.9818\n","Epoch 39/40 - Loss: 0.0944 - Accuracy: 0.9693\n","Epoch 40/40 - Loss: 0.1238 - Accuracy: 0.9551\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Definir o modelo\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(64 * 56 * 56, 128),  # Corrigir o tamanho da camada de entrada\n","            nn.ReLU(),\n","            nn.Linear(128, 3)  # Alterar o número de classes para 3\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc_layers(x)\n","        return x\n","\n","def accuracy(outputs, labels):\n","    _, predicted = torch.max(outputs, dim=1)\n","    correct = (predicted == labels).sum().item()\n","    total = labels.size(0)\n","    return correct / total\n","\n","\n","# Definir o diretório dos dados\n","data_dir = '/content/drive/Shareddrives/IC - Datasets/dataset/lens/'\n","train_data_file = os.path.join(data_dir, 'CogentAnnotationTrain.csv')\n","test_data_file = os.path.join(data_dir, 'CogentAnnotationTest.csv')\n","\n","\n","\n","# Criar instância do modelo\n","model =  EfficientNet.from_pretrained('efficientnet-b3')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Definir função de perda e otimizador\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","\n","# Função de treinamento\n","def train(model, train_loader, criterion, optimizer, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        running_accuracy = 0.0\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)  # Mover os dados de entrada para a GPU\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            running_accuracy += accuracy(outputs, labels)\n","        epoch_loss = running_loss / len(train_loader)\n","        epoch_accuracy = running_accuracy / len(train_loader)\n","        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f}\")\n","\n","\n","\n","\n","# Treinar o modelo\n","train(model, train_loader, criterion, optimizer, 40)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6915,"status":"ok","timestamp":1690938406947,"user":{"displayName":"LUCAS CHAGAS MOREIRA","userId":"17970820584704249691"},"user_tz":180},"id":"GlelAywpwub8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0712feb4-594f-42b0-8913-67fdb6223cdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 1.4564 - Test Accuracy: 0.6791\n"]}],"source":["def test(model, test_loader, criterion):\n","    model.eval()\n","    running_loss = 0.0\n","    running_accuracy = 0.0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)  # Mover os dados de entrada para a GPU\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            running_loss += loss.item()\n","            running_accuracy += accuracy(outputs, labels)\n","    test_loss = running_loss / len(test_loader)\n","    test_accuracy = running_accuracy / len(test_loader)\n","    print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n","\n","\n","\n","\n","# Testar o modelo\n","test(model, test_loader, criterion)"]},{"cell_type":"markdown","metadata":{"id":"ZNUyhEAZ-9Mv"},"source":["# Nova seção"]},{"cell_type":"markdown","source":[],"metadata":{"id":"J85VVqQr0FsB"}}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"mount_file_id":"1aHfeoMI13EpzTjweh9L0PkT5BrhMUl-u","authorship_tag":"ABX9TyPNRDx4fV7GM6z9mbJ9GzIW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}